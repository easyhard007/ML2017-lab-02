{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31354, 15349, 7428, 29880, 30865, 29794, 8394, 27781, 30493, 27458, 30239, 2054, 24844, 14041, 13585, 20514, 8260, 24338, 3070, 15456]\n",
      " loss test adadelta: 0.25\n",
      " loss test adadelta: 0.152637052008\n",
      " loss test adadelta: 0.139813025287\n",
      " loss test adadelta: 0.126815847\n",
      " loss test adadelta: 0.123934805471\n",
      " loss test adadelta: 0.119662846633\n",
      " loss test adadelta: 0.118972335948\n",
      " loss test adadelta: 0.115810662175\n",
      " loss test adadelta: 0.116181977195\n",
      " loss test adadelta: 0.111888709367\n",
      " loss test adadelta: 0.1154377691\n",
      " loss test adadelta: 0.108858838153\n",
      " loss test adadelta: 0.115795780562\n",
      " loss test adadelta: 0.114511183897\n",
      " loss test adadelta: 0.114945736829\n",
      " loss test adadelta: 0.113648218147\n",
      " loss test adadelta: 0.109719140445\n",
      " loss test adadelta: 0.116397948556\n",
      " loss test adadelta: 0.10838698357\n",
      " loss test adadelta: 0.111077139663\n",
      " loss test adadelta: 0.110923492921\n",
      " loss test adadelta: 0.110750453531\n",
      " loss test adadelta: 0.109601129456\n",
      " loss test adadelta: 0.107194338801\n",
      " loss test adadelta: 0.105543366026\n",
      " loss test adadelta: 0.110139550502\n",
      " loss test adadelta: 0.109000161176\n",
      " loss test adadelta: 0.107091488499\n",
      " loss test adadelta: 0.102815392472\n",
      " loss test adadelta: 0.104035678731\n",
      " loss test adadelta: 0.111878429023\n",
      " loss test adadelta: 0.106507758223\n",
      " loss test adadelta: 0.103398037845\n",
      " loss test adadelta: 0.106984939115\n",
      " loss test adadelta: 0.10582662612\n",
      " loss test adadelta: 0.111344188502\n",
      " loss test adadelta: 0.107032023363\n",
      " loss test adadelta: 0.0999257059431\n",
      " loss test adadelta: 0.105149170745\n",
      " loss test adadelta: 0.102403139343\n",
      "Features: [ -7.58300325e-01  -3.76785037e-01   1.12549984e-01   3.57165631e-01\n",
      "   2.51581398e-01  -3.75199078e-02  -2.66036719e-01   1.80762970e-01\n",
      "   1.69982591e-01  -6.70007869e-02  -6.63131080e-02  -6.95423663e-03\n",
      "  -1.07923442e-03  -1.99842504e-01  -5.12164640e-02  -4.05530858e-02\n",
      "  -7.10059303e-02  -5.11703653e-02   3.81096142e-02  -5.99639102e-02\n",
      "  -1.56867040e-01  -2.49022326e-01   2.31215218e-01   1.47033564e-02\n",
      "   4.08361008e-03  -1.22026633e-01  -1.91999033e-01  -3.85970674e-02\n",
      "   2.34934529e-01  -5.24200590e-02  -1.43382689e-01   1.91359651e-01\n",
      "  -9.62193693e-02  -1.76962027e-02  -8.19208093e-01  -2.49022326e-01\n",
      "  -5.99639102e-02   1.87869665e-02   6.95619013e-01   8.77977645e-01\n",
      "  -3.00664392e-01  -7.23128654e-01  -1.37389689e-01  -8.46447631e-02\n",
      "  -6.03928392e-02   1.44543432e-02   1.55158566e-01  -7.09796097e-02\n",
      "  -4.31049998e-01   1.19863127e-01   5.97302915e-01   4.23508295e-01\n",
      "  -2.31148144e-01  -2.36478498e-01  -6.06391031e-02  -2.91693898e-01\n",
      "  -1.24540005e-01  -2.77472033e-02   8.72173343e-02  -1.85297494e-03\n",
      "   5.86146813e-01  -5.39570189e-01   3.27227385e-01  -2.54200091e-01\n",
      "  -1.50389944e-01  -3.83002323e-01  -3.86000724e-02  -6.36381745e-02\n",
      "  -5.65052778e-02  -6.05135914e-02  -1.94531233e-01  -3.58090992e-01\n",
      "  -5.56973577e-02  -9.56829982e-01   5.43041632e-01  -6.74522043e-01\n",
      "   2.60733693e-01  -6.98638349e-01  -1.44114764e-01  -1.26432563e-01\n",
      "   1.83526406e-01   3.71870920e-01   2.87721200e-02   6.21967601e-03\n",
      "   8.82591191e-03  -2.44613010e-02   7.88170297e-03   1.05688180e-02\n",
      "  -5.39282625e-03  -9.81944777e-03   5.08354642e-03  -9.42077620e-03\n",
      "  -2.16966860e-02  -1.94126869e-02  -8.94492716e-04   7.57151515e-04\n",
      "  -1.79946916e-03   1.06869259e-02   9.47400790e-03  -9.28939786e-03\n",
      "  -8.39291436e-03  -2.21095898e-02  -1.69870337e-01  -9.00147794e-03\n",
      "   1.02788760e-03   5.77806751e-03  -1.86692235e-02  -4.17439840e-03\n",
      "  -6.27894987e-03  -3.96520709e-04  -7.50464488e-03  -2.28498101e-02\n",
      "  -1.70961287e-03  -1.11073338e-02  -9.82139534e-03  -3.49851796e-04\n",
      "  -3.43419717e-03   8.31422601e-04  -2.32493797e-02  -3.50612653e-03\n",
      "  -7.00532531e-03  -5.69889046e-04  -1.85960288e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e049e8eac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "\n",
    "eta = 0.05 # Learning Rate\n",
    "epsilon = 0.00001 #using in 4 optimalization methods to prevent the denominator become 0\n",
    "iter = 40 # Iteration times\n",
    "accuracy = 0.001 # If loss<accuracy , then stop iteration\n",
    "mini_batch_percent = 0.2\n",
    "\n",
    "m_train = 32561 # Amount of training data\n",
    "m_test = 16281 # Amount of testing data\n",
    "features=123 # Fearures of dataset\n",
    "\n",
    "#Initialize arrays\n",
    "w= [0]*features #All zero initialization\n",
    "\n",
    "#used to stastic and draw graph\n",
    "iter_num = [0]*iter;\n",
    "loss_train  = [0]*iter;\n",
    "loss_test_nag  = [0]*iter;\n",
    "loss_test_rmsprop  = [0]*iter;\n",
    "loss_test_adadelta  = [0]*iter;\n",
    "loss_test_adam  = [0]*iter;\n",
    "\n",
    "\n",
    "#used in adadelta\n",
    "sum_of_x_squared = 0\n",
    "sum_of_grad_squared = 0\n",
    "current = 0\n",
    "\n",
    "#used in adam\n",
    "mt = np.zeros(features)\n",
    "vt =0 \n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "\n",
    "#used in rmsProp\n",
    "Eg2 = 0\n",
    "\n",
    "#used in NAG\n",
    "v = np.zeros(features)\n",
    "miu = 0.9\n",
    "\n",
    "def  squared(vector):\n",
    "    a = np.mat(vector)\n",
    "    b = a*a.T\n",
    "    return b[0][0]\n",
    "\n",
    "#Use to get dataset from file\n",
    "def get_data():\n",
    "    data_train = load_svmlight_file(\"dataset\\\\a9a\",n_features=features)\n",
    "    X_train = data_train[0].toarray()\n",
    "    y_train = data_train[1]\n",
    "    data_test = load_svmlight_file(\"dataset\\\\a9a.t\",n_features=features)\n",
    "    X_test = data_test[0].toarray()\n",
    "    y_test = data_test[1]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "#The linear model, hw(x) = g(w.T * x)\n",
    "def hypothesis(x):\n",
    "    global w\n",
    "    z =   np.mat(x) * np.mat(w).T\n",
    "    z = z[0,0]\n",
    "    result = 1.0 / (1+(np.e**(-z)))\n",
    "    return result\n",
    "\n",
    "\n",
    "#Loss function \n",
    "def loss(m,X,y):\n",
    "    global w\n",
    "    result = 0.0\n",
    "    w2 = np.mat(w)\n",
    "    for i in range (0,m):\n",
    "        x = np.mat(X[i])\n",
    "        result += np.log(1+np.e**(-(X[i] * w2.T)[0,0]*y[i]))\n",
    "    result = result /m \n",
    "    return result\n",
    "\n",
    "def simple_loss(m,X,y):\n",
    "    global w\n",
    "    result = 0.0\n",
    "    \n",
    "    sample_num =math.ceil( m * mini_batch_percent)\n",
    "    target=random.sample(range(0,m),sample_num)\n",
    "    w2 = np.mat(w)\n",
    "    \n",
    "    for index in range (0,sample_num):\n",
    "        i = target[index]\n",
    "        x = np.mat(X[i])\n",
    "        result += ( hypothesis(X[i]) - (y[i]+1)/2 ) ** 2\n",
    "        \n",
    "    result = result / sample_num \n",
    "    return result\n",
    "\n",
    "#mini -batch loss function  \n",
    "def SGD_loss(m,X,y):\n",
    "    global w\n",
    "    result = 0.0\n",
    "    \n",
    "    sample_num =math.ceil( m * mini_batch_percent)\n",
    "    target=random.sample(range(0,m),sample_num)\n",
    "    w2 = np.mat(w)\n",
    "    \n",
    "    for index in range (0,sample_num):\n",
    "        i = target[index]\n",
    "        x = np.mat(X[i])\n",
    "        result += np.log(1+np.e**(-(X[i] * w2.T)[0,0]*y[i]))\n",
    "        \n",
    "    result = result / sample_num \n",
    "    return result\n",
    "\n",
    "\n",
    "def update(m,X,y,method):\n",
    "    global w\n",
    "    if (method=='nag'):\n",
    "        grad = SGD_grad(m,X,y)\n",
    "        w = w + NAG(grad)\n",
    "    if (method=='rmsprop'):\n",
    "        grad = SGD_grad(m,X,y)\n",
    "        w = w + rmsProp(grad)\n",
    "    if (method=='adadelta'):\n",
    "        grad = SGD_grad(m,X,y)\n",
    "        w = w + adadelta(grad)\n",
    "    if (method=='adam'):\n",
    "        grad = SGD_grad(m,X,y)\n",
    "        w = w + adam(grad)\n",
    "    \n",
    "def raw(grad):\n",
    "    return -eta * grad\n",
    "\n",
    "\n",
    "def adadelta(grad):\n",
    "    global sum_of_grad_squared, sum_of_x_squared, current\n",
    "    sum_of_grad_squared += squared(grad)\n",
    "    grad2 = np.mat(grad)\n",
    "    delta_x_mat =  -1* grad2\n",
    "    \n",
    "    if(current==0):\n",
    "        current+=1\n",
    "        delta_x_mat = -1*  grad2\n",
    "    else:\n",
    "        RMS_delta_x = math.sqrt(sum_of_x_squared/current)\n",
    "        RMS_grad = math.sqrt(sum_of_grad_squared/(current+1))\n",
    "        alpha = -1.0 * ( RMS_delta_x / RMS_grad)\n",
    "        delta_x_mat = alpha * grad2\n",
    "        current+=1\n",
    "    sum_of_x_squared += squared(delta_x_mat.getA1())\n",
    "    \n",
    "    \n",
    "    return delta_x_mat.getA1()\n",
    "\n",
    "def adam(grad):\n",
    "    global beta1,beta2,mt,vt,epsilon,current\n",
    "    current+=1\n",
    "    delta_x = [0]*features\n",
    "    grad2 = np.mat(grad)\n",
    "    mt = beta1 * mt + (1-beta1)*(grad2)\n",
    "    vt = beta2 * vt + (1-beta2)*( (grad2 * grad2.T)[0,0])\n",
    "    delta_x_mat = -eta * (math.sqrt(1-beta2**current)/(1-beta1**current))*(mt/(math.sqrt(vt)+epsilon)) \n",
    "    \n",
    "    return delta_x_mat.getA1()\n",
    "    \n",
    "def rmsProp(grad):\n",
    "    global Eg2\n",
    "    grad2 = np.mat(grad)\n",
    "    gt2 = (grad2 * grad2.T)[0,0]\n",
    "    Eg2 =  0.9 * Eg2 + 0.1 * gt2\n",
    "    delta_x_mat =  -eta / (math.sqrt(Eg2+epsilon)) *(grad2)\n",
    "    return delta_x_mat.getA1()\n",
    "    \n",
    "def NAG(grad):\n",
    "    global v,eta,miu\n",
    "    grad2 = np.mat(grad)\n",
    "    v = miu * v  - eta * grad2\n",
    "    return v.getA1()\n",
    "    \n",
    "\n",
    "#Derivative the Loss function to get Gradient (G) of theta j\n",
    "def grad(m,X,y):\n",
    "    result = np.zeros(features);\n",
    "    for i in range (0,m):\n",
    "        result +=  (hypothesis(X[i]) - (y[i]+1)/2) *X[i]\n",
    "    result = result / m\n",
    "    return result\n",
    "\n",
    "#Derivative the Loss function to get Gradient (G) of theta j\n",
    "def SGD_grad(m,X,y):\n",
    "    result = np.zeros(features);\n",
    "    \n",
    "    sample_num =math.ceil( m * mini_batch_percent)\n",
    "    #target = np.random.permutation(m)[0:sample_num]\n",
    "    target=random.sample(range(0,m),sample_num)\n",
    "    for index in range (0,sample_num):\n",
    "        i = target[index]\n",
    "        result +=  (hypothesis(X[i]) - (y[i]+1)/2)*X[i]\n",
    "        \n",
    "    result = result / m\n",
    "    return result\n",
    "\n",
    "\n",
    "#Train and validate \n",
    "def trainAndTest():\n",
    "    global w\n",
    "    '''\n",
    "    for i in range (0,iter):\n",
    "        iter_num[i] = i;\n",
    "                   \n",
    "        loss_test_nag[i] =  simple_loss(m_test,X_test,y_test)\n",
    "        print(\" loss test nag:\",loss_test_nag[i]);\n",
    "        \n",
    "        for j in range (0,10):\n",
    "            update(m_train,X_train,y_train,'nag')\n",
    "    \n",
    "    w = [0]*features\n",
    "  \n",
    "    for i in range (0,iter):\n",
    "        iter_num[i] = i;\n",
    "                   \n",
    "        loss_test_rmsprop[i] =  simple_loss(m_test,X_test,y_test)\n",
    "        print(\" loss test rmsProp:\",loss_test_rmsprop[i]);\n",
    "        \n",
    "        for j in range (0,10):\n",
    "            update(m_train,X_train,y_train,'rmsprop')\n",
    "    \n",
    "    w = [0]*features    \n",
    "    '''\n",
    "    for i in range (0,iter):\n",
    "        iter_num[i] = i;\n",
    "\n",
    "        loss_test_adadelta[i] =  simple_loss(m_test,X_test,y_test)\n",
    "        print(\" loss test adadelta:\", loss_test_adadelta[i]);\n",
    "        \n",
    "        for j in range (0,10):\n",
    "            update(m_train,X_train,y_train,'adadelta')\n",
    "    '''\n",
    "    w = [0]*features\n",
    "            \n",
    "    for i in range (0,iter):\n",
    "        iter_num[i] = i;\n",
    "                   \n",
    "        loss_test_adam[i] =  simple_loss(m_test,X_test,y_test)\n",
    "        print(\" loss test adam:\",loss_test_adam[i]);\n",
    "        \n",
    "        for j in range (0,10):\n",
    "            update(m_train,X_train,y_train,'adam')\n",
    "      '''\n",
    "#test\n",
    "resultList=random.sample(range(0,m_train),20)\n",
    "print(resultList)\n",
    "\n",
    "\n",
    "#Main \n",
    "X_train, y_train, X_test, y_test = get_data()\n",
    "\n",
    "'''\n",
    "m_train = 100\n",
    "X_train = X_train[0:100]\n",
    "y_train = y_train[0:100]\n",
    "'''\n",
    "trainAndTest()\n",
    "\n",
    "\n",
    "\n",
    "#Print the information and draw graphs\n",
    "print(\"Features:\",w)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(iter_num, loss_test_nag,  label='loss of NAG')\n",
    "ax.plot(iter_num, loss_test_rmsprop,  label='loss of RMSProp')\n",
    "ax.plot(iter_num, loss_test_adadelta,  label='loss of AdaDelta')\n",
    "ax.plot(iter_num, loss_test_adam,  label='loss of Adam')\n",
    "plt.legend(bbox_to_anchor=[1, 1])  \n",
    "ax.set_xlabel('Iteration times')\n",
    "ax.set_ylabel('Loss')\n",
    "plt.show()  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
